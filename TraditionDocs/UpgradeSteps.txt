--> Create the new 19c database.
--> Create the tablespaces.

CREATE BIGFILE TABLESPACE DATA10M DATAFILE '+TSTFX_DATA01' SIZE 10G AUTOEXTEND ON NEXT 50M MAXSIZE 500G LOGGING ONLINE EXTENT MANAGEMENT LOCAL AUTOALLOCATE BLOCKSIZE 8K SEGMENT SPACE MANAGEMENT AUTO FLASHBACK ON;
CREATE BIGFILE TABLESPACE DATA128K DATAFILE '+TSTFX_DATA01' SIZE 5G AUTOEXTEND ON NEXT 50M MAXSIZE 100G LOGGING ONLINE EXTENT MANAGEMENT LOCAL AUTOALLOCATE BLOCKSIZE 8K SEGMENT SPACE MANAGEMENT AUTO FLASHBACK ON;
CREATE BIGFILE TABLESPACE DATA1M DATAFILE '+TSTFX_DATA01' SIZE 5G AUTOEXTEND ON NEXT 50M MAXSIZE 100G LOGGING ONLINE EXTENT MANAGEMENT LOCAL AUTOALLOCATE BLOCKSIZE 8K SEGMENT SPACE MANAGEMENT AUTO FLASHBACK ON;
CREATE BIGFILE TABLESPACE INDX DATAFILE '+TSTFX_DATA01' SIZE 5G AUTOEXTEND ON NEXT 50M MAXSIZE 100G LOGGING ONLINE EXTENT MANAGEMENT LOCAL AUTOALLOCATE BLOCKSIZE 8K SEGMENT SPACE MANAGEMENT AUTO FLASHBACK ON;
CREATE BIGFILE TABLESPACE INDX10M DATAFILE '+TSTFX_DATA01' SIZE 5G AUTOEXTEND ON NEXT 50M MAXSIZE 25G LOGGING ONLINE EXTENT MANAGEMENT LOCAL AUTOALLOCATE BLOCKSIZE 8K SEGMENT SPACE MANAGEMENT AUTO FLASHBACK ON;
CREATE BIGFILE TABLESPACE INDX32K DATAFILE '+TSTFX_DATA01' SIZE 5G AUTOEXTEND ON NEXT 50M MAXSIZE 25G LOGGING ONLINE EXTENT MANAGEMENT LOCAL AUTOALLOCATE BLOCKSIZE 8K SEGMENT SPACE MANAGEMENT AUTO FLASHBACK ON;
CREATE BIGFILE TABLESPACE SPLEX_DATA DATAFILE '+TSTFX_DATA01' SIZE 500M AUTOEXTEND ON NEXT 50M MAXSIZE 2G LOGGING ONLINE EXTENT MANAGEMENT LOCAL AUTOALLOCATE BLOCKSIZE 8K SEGMENT SPACE MANAGEMENT AUTO FLASHBACK ON;
CREATE BIGFILE TABLESPACE SPLEX_IDX DATAFILE '+TSTFX_DATA01' SIZE 500M AUTOEXTEND ON NEXT 50M MAXSIZE 2G LOGGING ONLINE EXTENT MANAGEMENT LOCAL AUTOALLOCATE BLOCKSIZE 8K SEGMENT SPACE MANAGEMENT AUTO FLASHBACK ON;
CREATE TABLESPACE TOOLS DATAFILE '+TSTFX_DATA01' SIZE 500M AUTOEXTEND ON NEXT 50M MAXSIZE 2G LOGGING ONLINE EXTENT MANAGEMENT LOCAL AUTOALLOCATE BLOCKSIZE 8K SEGMENT SPACE MANAGEMENT AUTO FLASHBACK ON;
CREATE BIGFILE TABLESPACE AQ DATAFILE '+TSTFX_DATA01' SIZE 500M AUTOEXTEND ON NEXT 50M MAXSIZE 2G LOGGING ONLINE EXTENT MANAGEMENT LOCAL AUTOALLOCATE BLOCKSIZE 8K SEGMENT SPACE MANAGEMENT AUTO FLASHBACK ON;



--> Create a metadata dump file for all users except the oracle ones.

set pagesize 0;
set lines 250;
set heading off;
set feedback off;
set newpage none;
SET TRIMSPOOL ON
SET TRIMOUT ON
set space 0;
spool users_final.par
select username ||',' from dba_users where username not in ('ANONYMOUS'
,'APEX_040200'
,'APEX_PUBLIC_USER'
,'APPQOSSYS'
,'AUDSYS'
,'BI'
,'CTXSYS'
,'DBSNMP'
,'DIP'
,'DVF'
,'DVSYS'
,'EXFSYS'
,'FLOWS_FILES'
,'GSMADMIN_INTERNAL'
,'GSMCATUSER'
,'GSMUSER'
,'HR'
,'IX'
,'LBACSYS'
,'MDDATA'
,'MDSYS'
,'OE'
,'ORACLE_OCM'
,'ORDDATA'
,'ORDPLUGINS'
,'ORDSYS'
,'OUTLN'
,'PM'
,'SCOTT'
,'SH'
,'SI_INFORMTN_SCHEMA'
,'SPATIAL_CSW_ADMIN_USR'
,'SPATIAL_WFS_ADMIN_USR'
,'SYS'
,'SYSBACKUP'
,'SYSDG'
,'SYSKM'
,'SYSTEM'
,'WMSYS'
,'XDB'
,'SYSMAN'
,'RMAN'
,'RMAN_BACKUP'
,'OWBSYS'
,'OWBSYS_AUDIT'
,'APEX_030200'
,'MGMT_VIEW'
,'OJVMSYS'
,'FOGMON'
,'PERFSTAT'
,'QUEST'
,'SYSRAC'
,'XS$NULL'
,'GSMROOTUSER'
,'REMOTE_SCHEDULER_AGENT'
,'DBSFWUSER'
,'SYS$UMF'
,'GGSYS'
,'OLAPSYS'
,'TFS');


--> ship the dumpfile to target server.
--> Create the BLOTTER USER, AQMANAGER, OTHER ROLES by using DDL from TOAD. Use the below query to identify the roles involved. --> this is the important as the the users exported above will be granted the roles when you import them in the next step

select role from dba_roles where role not in (
'ACCHK_READ','DV_PATCH_ADMIN','MAINTPLAN_APP','ADM_PARALLEL_EXECUTE_TASK','DV_POLICY_OWNER','OEM_ADVISOR','APPLICATION_TRACE_VIEWER','DV_SECANALYST','OEM_MONITOR','AQ_ADMINISTRATOR_ROLE','DV_STREAMS_ADMIN','OLAP_DBA','AQ_USER_ROLE','DV_XSTREAM_ADMIN','OLAP_USER','AUDIT_ADMIN','EJBCLIENT','OLAP_XS_ADMIN','AUDIT_VIEWER','EM_EXPRESS_ALL','OPTIMIZER_PROCESSING_RATE','AUTHENTICATEDUSER','EM_EXPRESS_BASIC','ORDADMIN','AVTUNE_PKG_ROLE','EXECUTE_CATALOG_ROLE','PDB_DBA','
BDSQL_ADMIN','EXP_FULL_DATABASE','PPLB_ROLE','BDSQL_USER','GATHER_SYSTEM_STATISTICS','PROVISIONER','CAPTURE_ADMIN','GDS_CATALOG_SELECT','RDFCTX_ADMIN','CDB_DBA','GGSYS_ROLE','RECOVERY_CATALOG_OWNER','CONNECT','GLOBAL_AQ_USER_ROLE','RECOVERY_CATALOG_OWNER_VPD','CTXAPP','GSMADMIN_ROLE','RECOVERY_CATALOG_USER','DATAPATCH_ROLE','GSMROOTUSER_ROLE','RESOURCE','DATAPUMP_EXP_FULL_DATABASE','GSMUSER_ROLE','SCHEDULER_ADMIN','DATAPUMP_IMP_FULL_DATABASE','GSM_POOLADMIN_ROLE','SELECT_CATALOG_ROLE','DBA','HS_ADMIN_EXECUTE_ROLE','SODA_APP','DBFS_ROLE','HS_ADMIN_ROLE','SYSUMF_ROLE','DBJAVASCRIPT','HS_ADMIN_SELECT_ROLE','WM_ADMIN_ROLE','DBMS_MDX_INTERNAL','IMP_FULL_DATABASE','XDBADMIN','DV_ACCTMGR','JAVADEBUGPRIV','XDB_SET_INVOKER','DV_ADMIN','JAVAIDPRIV','XDB_WEBSERVICES','DV_AUDIT_CLEANUP','JAVASYSPRIV','XDB_WEBSERVICES_OVER_HTTP','DV_DATAPUMP_NETWORK_LINK','JAVAUSERPRIV','XDB_WEBSERVICES_WITH_PUBLIC','DV_GOLDENGATE_ADMIN','JAVA_ADMIN','XS_CACHE_ADMIN','DV_GOLDENGATE_REDO_ACCESS','JMXSERVER','XS_CONNECT','DV_MONITOR','LBAC_DBA','XS_NAMESPACE_ADMIN','DV_OWNER','LOGSTDBY_ADMINISTRATOR','XS_SESSION_ADMIN','DBA','DELETE_CATALOG_ROLE','JAVA_DEPLOY','XDBWEBSERVICES','SPLEX_ROLE_BOTH','WB_USER','SERVICE_USER','CDB_DBA','BDSQL_ADMIN','DATAPATCH_ROLE','DV_REALM_RESOURCE','DV_REALM_OWNER','DV_ACCTMGR','DV_OWNER','DV_PUBLIC');

--> Make sure the parameter SQLNET.ALLOWED_LOGON_VERSION_SERVER = 10 set in the sqlnet.ora file both in oracle home and grid home.

make the job_queue_processes parameter to 0

Now export TFS user metadata_only,

impdp directory=DATA_PUMP_DIR dumpfile=tfsmetadata_20211214.dmp sqlfile=tfs_table_metadata_20211214.sql exclude=SEQUENCE,PROCEDURE,DB_LINK,PACKAGE,TRIGGER,VIEW,FUNCTION,TYPE,STATISTICS,JAVA_CLASS,JAVA_SOURCE,PACKAGE_BODY,JOBS logfile=tfs_table_meta_20211214.log

add a script to create the "type" objects. --> look at  ld8tstsrv-fxdb07:/opt/contexts/backup/oracle/dpdump/UATFX25/types.sql for example. --> not needed types will be imported in the step above.

--> create /tmp,tfs,applog directory.

CREATE OR REPLACE DIRECTORY 
"/tfs/common" AS 
'/tfs/common'
/


CREATE OR REPLACE DIRECTORY 
"/tfs/fx.o/examples" AS 
'/tfs/fx.options/examples'
/


CREATE OR REPLACE DIRECTORY 
"/tfs/fx.o/printspool" AS 
'/tfs/tfs/common/spool/TFSWEQQ'
/


CREATE OR REPLACE DIRECTORY 
"/tfs/fx.o/sch/admin" AS 
'/tfs/fx.options/schemas/admin'
/


CREATE OR REPLACE DIRECTORY 
"/tfs/fx.o/sch/common" AS 
'/tfs/fx.options/schemas/common'
/


CREATE OR REPLACE DIRECTORY 
"/tfs/fx.o/sch/interests" AS 
'/tfs/fx.options/schemas/interests'
/


CREATE OR REPLACE DIRECTORY 
"/tfs/fx.o/sch/tables" AS 
'/tfs/fx.options/schemas/tables'
/


CREATE OR REPLACE DIRECTORY 
"/tfs/fx.o/sch/trades" AS 
'/tfs/fx.options/schemas/trades'
/


CREATE OR REPLACE DIRECTORY 
"/tfs/fx.o/transform" AS 
'/tfs/fx.options/transforms'
/


CREATE OR REPLACE DIRECTORY 
"/tfs/fx.o/transforms" AS 
'/tfs/fx.options/transforms'
/


CREATE OR REPLACE DIRECTORY 
"/tmp" AS 
'/tmp'
/


CREATE OR REPLACE DIRECTORY 
APPLOG AS 
'/opt/oracle/applogs'
/


CREATE OR REPLACE DIRECTORY 
"AppLog" AS 
'/opt/oracle/applogs'
/


GRANT READ, WRITE ON DIRECTORY "/tfs/common" TO BLOTTER_USER
/

GRANT READ, WRITE ON DIRECTORY "/tfs/fx.o/examples" TO BLOTTER_USER
/

GRANT READ, WRITE ON DIRECTORY "/tfs/fx.o/printspool" TO BLOTTER_USER
/

GRANT READ, WRITE ON DIRECTORY "/tfs/fx.o/sch/admin" TO BLOTTER_USER
/

GRANT READ, WRITE ON DIRECTORY "/tfs/fx.o/sch/common" TO BLOTTER_USER
/

GRANT READ, WRITE ON DIRECTORY "/tfs/fx.o/sch/interests" TO BLOTTER_USER
/

GRANT READ, WRITE ON DIRECTORY "/tfs/fx.o/sch/tables" TO BLOTTER_USER
/

GRANT READ, WRITE ON DIRECTORY "/tfs/fx.o/sch/trades" TO BLOTTER_USER
/

GRANT READ, WRITE ON DIRECTORY "/tfs/fx.o/transforms" TO BLOTTER_USER
/

GRANT READ, WRITE ON DIRECTORY "/tmp" TO BLOTTER_USER
/

GRANT READ, WRITE ON DIRECTORY "AppLog" TO BLOTTER_USER
/

GRANT EXECUTE, READ, WRITE ON DIRECTORY "/tfs/common" TO SYSTEM WITH GRANT OPTION
/

GRANT EXECUTE, READ, WRITE ON DIRECTORY "/tfs/fx.o/examples" TO SYSTEM WITH GRANT OPTION
/

GRANT EXECUTE, READ, WRITE ON DIRECTORY "/tfs/fx.o/printspool" TO SYSTEM WITH GRANT OPTION
/

GRANT EXECUTE, READ, WRITE ON DIRECTORY "/tfs/fx.o/sch/admin" TO SYSTEM WITH GRANT OPTION
/

GRANT EXECUTE, READ, WRITE ON DIRECTORY "/tfs/fx.o/sch/common" TO SYSTEM WITH GRANT OPTION
/

GRANT EXECUTE, READ, WRITE ON DIRECTORY "/tfs/fx.o/sch/interests" TO SYSTEM WITH GRANT OPTION
/

GRANT EXECUTE, READ, WRITE ON DIRECTORY "/tfs/fx.o/sch/tables" TO SYSTEM WITH GRANT OPTION
/

GRANT EXECUTE, READ, WRITE ON DIRECTORY "/tfs/fx.o/sch/trades" TO SYSTEM WITH GRANT OPTION
/

GRANT EXECUTE, READ, WRITE ON DIRECTORY "/tfs/fx.o/transform" TO SYSTEM WITH GRANT OPTION
/

GRANT EXECUTE, READ, WRITE ON DIRECTORY "/tfs/fx.o/transforms" TO SYSTEM WITH GRANT OPTION
/

GRANT EXECUTE, READ, WRITE ON DIRECTORY "/tmp" TO SYSTEM WITH GRANT OPTION
/

GRANT EXECUTE, READ, WRITE ON DIRECTORY "AppLog" TO SYSTEM WITH GRANT OPTION
/

GRANT READ, WRITE ON DIRECTORY "/tfs/common" TO TFS WITH GRANT OPTION
/

GRANT READ, WRITE ON DIRECTORY "/tfs/fx.o/examples" TO TFS WITH GRANT OPTION
/

GRANT READ, WRITE ON DIRECTORY "/tfs/fx.o/printspool" TO TFS WITH GRANT OPTION
/

GRANT READ, WRITE ON DIRECTORY "/tfs/fx.o/sch/admin" TO TFS WITH GRANT OPTION
/

GRANT READ, WRITE ON DIRECTORY "/tfs/fx.o/sch/common" TO TFS WITH GRANT OPTION
/

GRANT READ, WRITE ON DIRECTORY "/tfs/fx.o/sch/interests" TO TFS WITH GRANT OPTION
/

GRANT READ, WRITE ON DIRECTORY "/tfs/fx.o/sch/tables" TO TFS WITH GRANT OPTION
/

GRANT READ, WRITE ON DIRECTORY "/tfs/fx.o/sch/trades" TO TFS WITH GRANT OPTION
/

GRANT READ, WRITE ON DIRECTORY "/tfs/fx.o/transform" TO TFS WITH GRANT OPTION
/

GRANT READ, WRITE ON DIRECTORY "/tfs/fx.o/transforms" TO TFS WITH GRANT OPTION
/

GRANT EXECUTE, READ, WRITE ON DIRECTORY "/tmp" TO TFS WITH GRANT OPTION
/

GRANT READ, WRITE ON DIRECTORY "AppLog" TO TFS WITH GRANT OPTION
/


Create The TFS user with the sql file generated above and then add a few other important privileges like below. Take the exact queries from the DDL script for TFS user. This is very important as a lot of packages/views being valid depends on this.

-- 6 Roles for TFS 
GRANT AQ_ADMINISTRATOR_ROLE TO TFS
/
GRANT AQ_USER_ROLE TO TFS
/
GRANT BLOTTER_USER TO TFS
/
GRANT CONNECT TO TFS
/
GRANT JAVAUSERPRIV TO TFS
/
GRANT RESOURCE TO TFS
/
ALTER USER TFS DEFAULT ROLE ALL
/

-- 20 System Privileges for TFS 
GRANT ADMINISTER DATABASE TRIGGER TO TFS
/
GRANT ALTER SESSION TO TFS
/
GRANT ALTER SYSTEM TO TFS
/
GRANT ALTER USER TO TFS
/
GRANT CREATE ANY DIRECTORY TO TFS
/
GRANT CREATE DATABASE LINK TO TFS
/
GRANT CREATE PUBLIC SYNONYM TO TFS
/
GRANT CREATE SESSION TO TFS
/
GRANT CREATE USER TO TFS
/
GRANT CREATE VIEW TO TFS
/
GRANT DEBUG ANY PROCEDURE TO TFS
/
GRANT DEBUG CONNECT SESSION TO TFS
/
BEGIN
SYS.DBMS_AQADM.GRANT_SYSTEM_PRIVILEGE (
  PRIVILEGE    => 'DEQUEUE_ANY',
  GRANTEE      => 'TFS',
  ADMIN_OPTION => FALSE);
END;
/
GRANT DROP ANY DIRECTORY TO TFS
/
BEGIN
SYS.DBMS_AQADM.GRANT_SYSTEM_PRIVILEGE (
  PRIVILEGE    => 'ENQUEUE_ANY',
  GRANTEE      => 'TFS',
  ADMIN_OPTION => FALSE);
END;
/
GRANT GRANT ANY PRIVILEGE TO TFS
/
GRANT GRANT ANY ROLE TO TFS
/
BEGIN
SYS.DBMS_AQADM.GRANT_SYSTEM_PRIVILEGE (
  PRIVILEGE    => 'MANAGE_ANY',
  GRANTEE      => 'TFS',
  ADMIN_OPTION => FALSE);
END;
/
GRANT SELECT ANY TABLE TO TFS
/
GRANT UNLIMITED TABLESPACE TO TFS
/

-- 31 Object Privileges for TFS 
GRANT EXECUTE, READ, WRITE ON DIRECTORY "/tmp" TO TFS
/
GRANT READ, WRITE ON DIRECTORY "AppLog" TO TFS
/
GRANT READ, WRITE ON DIRECTORY BACKUP_DIR TO TFS
/
GRANT READ, WRITE ON DIRECTORY DATA_PUMP_DIR TO TFS
/
GRANT SELECT ON SYS.DBA_JOBS TO TFS WITH GRANT OPTION
/
GRANT SELECT ON SYS.DBA_JOBS_RUNNING TO TFS WITH GRANT OPTION
/
GRANT SELECT ON SYS.DBA_ROLES TO TFS WITH GRANT OPTION
/
GRANT SELECT ON SYS.DBA_ROLE_PRIVS TO TFS WITH GRANT OPTION
/
GRANT SELECT ON SYS.DBA_SCHEDULER_JOBS TO TFS
/
GRANT SELECT ON SYS.DBA_SCHEDULER_JOB_LOG TO TFS
/
GRANT SELECT ON SYS.DBA_SYS_PRIVS TO TFS WITH GRANT OPTION
/
GRANT SELECT ON SYS.DBA_USERS TO TFS
/
GRANT EXECUTE ON SYS.DBMS_ALERT TO TFS WITH GRANT OPTION
/
GRANT EXECUTE ON SYS.DBMS_AQ TO TFS
/
GRANT EXECUTE ON SYS.DBMS_AQADM TO TFS
/
GRANT EXECUTE ON SYS.DBMS_LOCK TO TFS WITH GRANT OPTION
/
GRANT EXECUTE ON SYS.DBMS_PIPE TO TFS WITH GRANT OPTION
/
GRANT READ, WRITE ON DIRECTORY SCRIPT_DIR TO TFS
/
GRANT EXECUTE, READ, WRITE ON DIRECTORY TFS TO TFS
/
GRANT SELECT ON SYS.USER$ TO TFS
/
GRANT EXECUTE ON SYS.UTL_HTTP TO TFS
/
GRANT SELECT ON SYS.V_$DATABASE TO TFS WITH GRANT OPTION
/
GRANT SELECT ON SYS.V_$MYSTAT TO TFS WITH GRANT OPTION
/
GRANT SELECT ON SYS.V_$PROCESS TO TFS WITH GRANT OPTION
/
GRANT SELECT ON SYS.V_$SCHEDULER_RUNNING_JOBS TO TFS
/
GRANT SELECT ON SYS.V_$SESSION TO TFS WITH GRANT OPTION
/
GRANT SELECT ON SYS.V_$SESSTAT TO TFS WITH GRANT OPTION
/
GRANT SELECT ON SYS.V_$STATNAME TO TFS WITH GRANT OPTION
/
GRANT SELECT ON SYS.V_$TRANSACTION TO TFS
/

GRANT CREATE ANY JOB TO "TFS";
GRANT CREATE JOB TO "TFS";
GRANT EXECUTE ON SYS.DBMS_IJOB to TFS;
grant select on sys.user_jobs to tfs with grant option;

Then modify the Tables to use binary storage and create them. 

Then import the rest of the metadata. 

impdp directory=DATA_PUMP_DIR dumpfile=tfsmetadata.dmp logfile=tfsmetada_imp_run1.log table_exists_action=truncate

Make sure all the packages,views, package bodies are valid. and create synonyms for all the pakages.

begin   for x in (select 'create public synonym '||object_name||' for TFS.'||object_name as cr_syn from user_objects where object_type = 'PACKAGE')   loop      execute immediate x.cr_syn;   end loop;end;

Because the tables are created in advance all dependent objects like indexes/constraints/triggers will be excluded. Make sure all the numbers match up.

impdp directory=DATA_PUMP_DIR dumpfile=tfsmetadata_20220324.dmp logfile=tfsmetada_imp_const.log include=constraint
impdp directory=DATA_PUMP_DIR dumpfile=tfsmetadata_20220324.dmp logfile=tfsmetada_imp_ind.log include=index
impdp directory=DATA_PUMP_DIR dumpfile=tfsmetadata_20220324.dmp logfile=tfsmetada_imp_trig.log include=trigger

Disable Referential key contraints and triggers before importing data.


You can then generate the SQL and run it or import it. you need to make sure the packages have been imported. As a rough check get a count of the objects from the source and compare with the target. see how many objects are invalid and see if you can validate them.

Disable database links
Create /tmp directory.


--> Get the impdp but with the sqlfile option.

impdp directory=DATA_PUMP_DIR dumpfile=fxmetadata.dmp sqlfile=fxmetadata.sql logfile=fxmetadata_2_sql.log

modify the above file to add
"grant alter session to QUEUEMGR;" to avoid ORA-31685: Object type PROCOBJ:<SCHEMA_NAME>.<SCHEDULER_JOB> failed due to insufficient privileges. 
"set define off"
spool logfile
Run the above SQL. try to minimise the errors.

Then disable all triggers and referential key constraints. 

Increase the UNDO tablespace size to 64GB.

import,

create directories
create NACL
create queue


modify Default profile password settings.
ALTER PROFILE DEFAULT LIMIT FAILED_LOGIN_ATTEMPTS UNLIMITED;
ALTER PROFILE DEFAULT LIMIT PASSWORD_LIFE_TIME UNLIMITED;


make sure clock is okay.

SET SPACE 1 LINESIZE 80 PAGES 1000
SELECT * FROM (
select to_char(ORIGINATING_TIMESTAMP,'YYYY/MM/DD HH24:MI:SS TZH:TZM')
from V$DIAG_ALERT_EXT
WHERE trim(COMPONENT_ID)='rdbms'
and MESSAGE_TEXT like ('PMON started with%')
order by originating_timestamp desc )
WHERE rownum < 20;


